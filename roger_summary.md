
上篇文章因为给新写的书打了广告，给版主封了。我理解和支持版主的工作，所以这篇只谈方法，只讲事实。

之前帮优秀的版友内推，也顺便结识了不少朋友，回答了一些大家的疑问。一个普遍的问题是：我cc150刷了两遍，leetcode刷了两遍，算准备好了么？还应该做什么题目？去看看EPI？是啊，其实我自己也在想，怎么样做题算是“够了”？就和准备高考一样，3年模拟题做完做5年的？本地的做完了做全国的？

我高中参加数学竞赛，然后得奖保送北大。那时具体的题目、公式都忘得差不多了，但学到了一点终生受益：要把做过的题目联系起来，然后总结方法。寻求为什么这么做，而不是怎么做。否则，不通过举一反三，而寄希望于在考试／面试时出现做过的内容，那就真是“以有崖求无崖，殆哉矣”。这里，我只谈方法。给个实例：

大家可能都觉得，算法题中动态规划是比较麻烦的问题。但当你碰到这类问题时，仔细总结过方法么？考虑过题目为什么要用动态规划么？动归和递归的区别在哪里？
我觉得，从子问题解决原问题, 无非是两种方法，自底向上(Bottom-Up)与自顶向下(Top-Down)，形式上前者对应iteration，利用循环将结果存在数组里，从数组起始位置向后计算；后者对应recursion，即利用函数调用自身实现，如果不储存上一个状态的解，则为递归，否则就是DP。举个斐波那契数列(0,1,1,2,3,5…)的例子：
1) 自底向上
int array[n] = {0};
array[1] = 1;
for (int i = 2; i < n; i++)
    array = array[i-1] + array[i-2];

事实上，额外空间可以进一步缩小到O(1)：利用几个变量记录之前的状态即可。由于记录了子问题的解，故给出的方法就是DP。事实上，自底向上的方式往往都是通过动态规划实现。 

2) 自顶向下
int Fibonacci(int n)
{
    if(n == 0)
        return 0;
    if(n == 1)
        return 1;
    return Fibonacci(n-1) + Fibonacci(n-2);
}

为计算Fibonacci的第n个元素，我们先自顶向下地计算子问题：第n-1个元素和第n-2个元素。由于没有储存子问题的运算结果，给出的方法是递归。然而，Fibonacci(n-1)与Fibonacci(n-2)包含很多重复的子问题，所以DP效率更高。如果用一个全局数组，将子问题的解储存到数组的对应位置，在重复计算的时候直接读取计算结果，那么就是DP的解法。

动态规划的核心在于，如果通往一个问题的solution，subproblem被重复计算，那么就可以利用记录中间结果，达到用空间换取时间的目的。在递归过程中用hash table记录中间计算结果的DP，称作Memoization。

Memoization的一般形式是: 建立以input为key，以output为value的hash table：
T func(N node, HashTable<N, T>& cache) {
    If (cache.contains(node)) {
        return cache.get(node);
    }
    …
    T sub_res = func(next_node, cache);
    …
    T res = G( sub_res … );  //当前子问题的解，依赖于更小的子问题(s)
    cache.set(node, res);
    return res;
}

从解决问题的角度来说，用Bottom-Up的DP，固然通常可以节省递归本身的空间开销，但有很多缺点和局限：较难理解，边界条件较难处理，只适用于问题的节点空间是离散的整数空间，必须一步步邻接、连续地计算(无论是不是每一个节点的结果都会被用到)。而Memoization，则灵活得多：可以从递归形式轻易修改得到，也更符合普遍的思维过程，并且没有上面说的这些局限，子问题只有在被需要的时候才会被计算。尤其是在某些情况下，不仅需要aggregate的结果，还需要获得achieve这个结果的路径，这时候就算用Bottom-Up的DP，也需要记录prev节点，最后需要递归回溯得到路径，那么节省递归空间开销的优势，也荡然无存了。

那么Bottom-Up的DP可以解决哪类问题？我说，DP适用于解决“收敛结构问题”。所谓的“收敛结构问题”是指关于特解，或数量的问题（例如，第n个元素，第n步有多少种方法等）。这些问题都可以用整数坐标映射所有节点（即DP状态），且当前节点的解只依赖于前驱节点(无论是顺序还是倒序)。那么，这类问题往往可以用DP解决。解决的关键是建立subproblem的解之间的递推关系：
f(n) = G[f(n-1), f(n-2), … , f(1)] 或
f(i, j) = G[f(i-1, j-1), f(i, j -1), f(i-1,j)]
其中G[ ]表示子问题到原问题的映射关系，例如对于斐波那契数列，有递推式：
f(n) = G[f(n-1), f(n-2)] = f(n-1) + f(n-2)

但如果出现类似于“所有解”，“所有路径”等关键词，则用Top-down方法更为直接。

举一道简单的题目： Suppose we have a ladder which has n steps. Each time you can either climb 1 or 2 steps. Please write a function to calculate how many distinct ways that can you climb to the top?

解题分析：本问题描述了一个数量问题，属于前述的强收敛(聚合)性问题，可以用DP。DP的核心在于递推关系：当前节点的值可以由前驱走一步到达，或者前前驱走两步到达，即CountOfWays(n) = CountOfWays(n–1) + CountOfWays(n-2)；由于当前节点只与紧邻的两个节点决定，所以只需要2个临时变量来表示前驱节点的解即可，而不用DP table，因为更老的解我们不需要关心。在实现时，往往边界条件直接用if…then return value的形式，成为递归的出口。

因此，当理解到了一定的深度，真不是特别在乎做了多少题目。与之相关的另一个问题是，准备周期得有多长？这里，我只谈事实。看过我之前文章的朋友也知道，我本来是考虑转博的，但后来打算直接工作。我那时一月底开始准备，二月底投简历，到四月底一共onsite了12家公司拿了10个offer。不否认我的基础还算不错，科研也和软件相关，但也不算科班出身，硕士是ECE（在面试google的时候也暴露了CS知识面不够广的问题，所以G家也是我唯一技术上没过的公司）。
但是，我们准备的时候极其认真，效率远远超过现在工作。特别是他为了节约时间，一天只吃固定东西：中午越南粉，晚上Jack in the box或者互换。谈事实的目的就是，如果真正投入加仔细思考方法，几个月搞定心仪的工作也不是不可能。就看你理解的有多深。
大家可以比较下思考的深度。他笔记里的思想后来成了我们书的原型。

只练不想还有两个问题：
1. 看到类似的题目就硬套方法。当面试官要求换个思路时会感觉很困难
2. 看到没见过的题目有时就会慌，结果连正常水平也没发挥出来。

总而言之，希望大家能换个方向看刷题，与其做上两遍，三遍，不如花相同的时间认真总结下适合自己的方法。
